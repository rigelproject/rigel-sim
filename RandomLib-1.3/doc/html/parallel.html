<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>RandomLib: Parallelization</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- Generated by Doxygen 1.7.4 -->
<div id="top">
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">RandomLib</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li><a href="dirs.html"><span>Directories</span></a></li>
    </ul>
  </div>
</div>
<div class="header">
  <div class="headertitle">
<div class="title">Parallelization </div>  </div>
</div>
<div class="contents">
<div class="textblock"><center> Back to <a class="el" href="programming.html">Programming tips</a>. Forward to <a class="el" href="function.html">Function index</a>. Up to <a class="el" href="index.html#contents">Contents</a>. </center><p>Many large codes are designed to run in parallel environments. The parallelization may be across the cores of a multi-core computer or across a cluster of computers. Some of the more-or-less portable methods for parallelization are</p>
<ul>
<li>C++0x threads or boost threads</li>
<li>the <a href="http://www.mcs.anl.gov/research/projects/mpi/">Message Passing Interface</a></li>
<li><a href="http://threadingbuildingblocks.org">Threading Building Blocks</a></li>
<li><a href="http://openmp.org">OpenMP</a></li>
</ul>
<p>I will use OpenMP to illustrate the techniques for paralleling <a class="el" href="namespaceRandomLib.html" title="Namespace for RandomLib.">RandomLib</a> because both g++ and Visual Studio support it and because it entails the least modification of a serial code. However the techniques are readily applied to the other parallelization methods listed above.</p>
<p>We can stipulate some goals for a parallel code which uses random numbers:</p>
<ol type="1">
<li>The result should be correct.</li>
<li>The program should make effective use of the computational resources.</li>
<li>Running the code twice with the same random number seed on the same hardware with the same number of processors should produce identical results.</li>
<li>Running the code twice with the same random number seed on the same hardware with a different number of processors should produce identical results.</li>
<li>Running the code twice with the same random number seed on the same hardware in a serial mode should produce identical results.</li>
</ol>
<p>Goal 1 requires (a) that updates to shared objects are properly protected by locks and (b) that the random numbers used by different threads are independent. There are three ways that (b) can be achieved:</p>
<ul>
<li>Different threads use a single Random object with access to it protect by a lock. The drawbacks to this approach are the potentially high cost of frequently locking the Random object and the impossibility of achieving goal 3 using such a scheme (since the order that different thread acquire the lock on the Random object will be indeterminate).</li>
<li>Different threads use copies of a single Random object (or more generally they use distinct Random objects which have the same seed), but they access non-overlapping sequences out of the Random object.</li>
<li>Different threads use distinct Random objects which have distinct seeds.</li>
</ul>
<p>We shall use a combination of the last two ways.</p>
<p>Achieving goal 2 depends on the problem. However, many applications using random numbers can be decomposed into many independent (or weakly dependent) pieces which can be run as separate threads. There will potentially be stalls in the threads waiting for locks to be released. In some cases, the overall throughput will be limited by some other critical resource, e.g., bandwidth to the disk. However, it's often possible to ensure that the all cores on a multiprocessor machine are busy and to speed up dramatically applications using random sampling.</p>
<p>The remaining goals, 3&ndash;5, concern the issues of being able to repeat a calculation possibly in a simpler environment for the purposes of validation, debugging, etc. For some applications, this may not matter. However, a Monte Carlo simulation of neutron transport in a fission reactor is an example of a code where it's very important to ensure that the code is correct and where it's easy to diagnose problems.</p>
<p>An example: estimate the volume of an <em>n</em>-dimensional unit sphere. A simple way to do this is to sample points uniformly in the enclosing <em>n</em>-dimensional cube and count how many of these points lie inside the sphere. The following code is a slight improvement to this where we integrate analytically in one of the dimensions. (These samples of code are taken from <a class="el" href="RandomThread_8cpp.html" title="Example of parallelization with RandomLib using threads.">RandomThread.cpp</a>.) </p>
<div class="fragment"><pre class="fragment"><span class="keywordtype">double</span> <a class="code" href="RandomThread_8cpp.html#a024c7494a4662027dc2d4312577f2bce">dotrials</a>(Random&amp; r, <span class="keywordtype">int</span> d, <span class="keywordtype">long</span> <span class="keywordtype">long</span> n) {
  <span class="comment">// Require d &gt; 0, n &gt; 0</span>
  <span class="keywordtype">double</span> w = 0;
  <span class="keywordflow">for</span> ( ; n--; ) {              <span class="comment">// Iterate n times</span>
    <span class="keywordtype">double</span> h = 0;
    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 1; i &lt; d; ++i) { <span class="comment">// Iterate d-1 times</span>
      <span class="keywordtype">double</span> x = 2 * r.FixedS();  <span class="comment">// x is in (-1, 1)</span>
      h += x * x;                 <span class="comment">// cumulative radius^2</span>
      <span class="keywordflow">if</span> (h &gt;= 1) <span class="keywordflow">break</span>;          <span class="comment">// Point can&#39;t be in sphere; bail out,</span>
    }
    <span class="comment">// If h &lt; 1 then inside a (d-1) dimensional unit sphere at radius</span>
    <span class="comment">// sqrt(h), so extent of last dimension is +/- sqrt(1 -h)</span>
    w += h &lt; 1 ? sqrt(1 - h) : 0;
  }
  <span class="keywordflow">return</span> w;
}

<span class="keywordtype">double</span> <a class="code" href="RandomThread_8cpp.html#aaefe54ce7a3b2b711e7bc311980bc4d7">result</a>(<span class="keywordtype">int</span> d, <span class="keywordtype">long</span> <span class="keywordtype">long</span> n, <span class="keywordtype">double</span> w) {
  <span class="comment">// Volume of (d-1) dimensional box = 2^(d-1).</span>
  <span class="comment">// Multiply by another 2 to account for +/- extent in last dimension.</span>
  <span class="keywordflow">return</span> double(1U &lt;&lt; d) * w / double(n);
}

<span class="keywordtype">int</span> <a class="code" href="RandomCoverage_8cpp.html#a2c3f6775325c30275d11c6abee2db6a0">main</a>() {
  <span class="keywordtype">int</span> d = 4;                    <span class="comment">// Number of dimensions</span>
  <span class="keywordtype">long</span> <span class="keywordtype">long</span> n = 100000000;      <span class="comment">// Number of trials 10^8</span>
  Random r; r.Reset();
  <span class="keywordtype">double</span> weight = <a class="code" href="RandomThread_8cpp.html#a024c7494a4662027dc2d4312577f2bce">dotrials</a>(r, d, n);
  <span class="keywordtype">double</span> volume = <a class="code" href="RandomThread_8cpp.html#aaefe54ce7a3b2b711e7bc311980bc4d7">result</a>(d, n, weight);
  cout &lt;&lt; volume &lt;&lt; <span class="stringliteral">&quot;\n&quot;</span>;
} 
</pre></div><p> I've divided the computation of the volume into two functions, dotrials and result, to aid in the exposition. Nearly all the time is spent in dotrials and, as it stands, the loops in this function cannot of executed in parallel because of the updates to the random number generator, <em>r</em>.</p>
<p>Convert this to a code which is ready for parallelization by making multiple calls to dotrials as follows </p>
<div class="fragment"><pre class="fragment"><span class="keywordtype">int</span> <a class="code" href="RandomCoverage_8cpp.html#a2c3f6775325c30275d11c6abee2db6a0">main</a>() {
  <span class="keywordtype">int</span> d = 4;                    <span class="comment">// Number of dimensions</span>
  <span class="keywordtype">long</span> <span class="keywordtype">long</span> n = 100000000;      <span class="comment">// Number of trials 10^8</span>
  <span class="keywordtype">int</span> k = 100;                  <span class="comment">// Number of tasks</span>
  vector&lt;double&gt; w(k);          <span class="comment">// Vector for partial weights</span>
  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; k; ++i) { <span class="comment">// the main loop over tasks</span>

    Random r;                   <span class="comment">// task specific Random</span>
    <span class="comment">// Initialize r in a task specific way ...</span>

    <span class="comment">// Do the work; last argument splits n exactly into k pieces</span>
    w[i] = <a class="code" href="RandomThread_8cpp.html#a024c7494a4662027dc2d4312577f2bce">dotrials</a>(r, d, (n * (i + 1))/k - (n * i)/k);
  }
  <span class="comment">// Sum up the weights from the individual tasks</span>
  <span class="keywordtype">double</span> weight = accumulate(w.begin(), w.end(), 0.0);
  <span class="comment">// Compute the result</span>
  <span class="keywordtype">double</span> volume = <a class="code" href="RandomThread_8cpp.html#aaefe54ce7a3b2b711e7bc311980bc4d7">result</a>(d, n, weight);
  cout &lt;&lt; volume &lt;&lt; <span class="stringliteral">&quot;\n&quot;</span>;
} 
</pre></div><p>The loop here splits the <em>n</em> samples into <em>k</em> independent <em>tasks</em>. This loop is a candidate for parallelization. First we need to decide on a suitable choice for <em>k</em> and on how the random number generators should be initialized. These need to address two issues:</p>
<ul>
<li>Efficiency: We can see from the following table that reseeding the generator is roughly as expensive as consuming 4000 random numbers from the generator. There may also be overhead in dealing with a large number of tiny tasks.</li>
<li>Statistical accuracy: A sequence of numbers produced by MT19937 or SFMT19937 with a given seed has some proven good statistical properties. Little is known about the properties of the sequence of numbers obtained when these generators are frequently reseeded.</li>
</ul>
<center> <table class="doxtable">
<caption align="bottom">Approximate relative times for basic seeding operations</caption>
<tr>
<th>Function </th><th>Relative time </th></tr>
<tr>
<td>s = Random::SeedWord(); </td><td>500000 </td></tr>
<tr>
<td>v = Random::SeedVector(); </td><td>10000 </td></tr>
<tr>
<td>r.Reseed(v), r.SetCount(0) </td><td>4000 </td></tr>
<tr>
<td>i = r(); </td><td>1 </td></tr>
<tr>
<td>r.StepCount(N); </td><td>abs(N)/3 </td></tr>
</table>
</center><p> In order to address efficiency, we should pick <em>k</em> small enough that we use at least 10<sup>4</sup> to 10<sup>5</sup> random numbers for each task. In order to preserve the statistical properties of SFMT19937, we should consume as many random numbers as possible for each task. (Incidentally, this table also shows the high cost of Random::SeedWord(). This is mainly because of accessing /dev/urandom. Typically you should call Random::SeedWord() at most once per code run.) In addition we should choose <em>k</em> large enough to spread the tasks out between the CPUs. It is good to choose <em>k</em> to be a several times the number of CPUs. This ensures good utilization of resources if some of the tasks complete more quickly than others (because they entail less computation or because some CPUs are faster than others); it also allows you to more your code to a larger machine (or group of machines) without adjusting <em>k</em>.</p>
<p>An obvious way to initialize the random generator for each task is to include the task number <em>i</em> in the seed. For example </p>
<div class="fragment"><pre class="fragment">  <span class="comment">// Set master_seed to a &quot;unique&quot; vector</span>
  vector&lt;unsigned long&gt; master_seed(Random::SeedVector());
  master_seed.push_back(0);     <span class="comment">// Reserve an additional slot</span>

  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; k; ++i) { <span class="comment">// the main loop over tasks</span>

    Random r;                   <span class="comment">// task specific Random</span>
    {
      vector&lt;unsigned long&gt; seed(master_seed); <span class="comment">// task specific seed</span>
      seed.back() = i;                         <span class="comment">// include task id in seed</span>
      r.Reseed(seed);
    }

    w[i] = <a class="code" href="RandomThread_8cpp.html#a024c7494a4662027dc2d4312577f2bce">dotrials</a>(r, d, (n * (i + 1))/k - (n * i)/k);
  }
</pre></div><p> Note the ease with which the seed can be made to depend on the task id &mdash; merely by appending it to the seed vector. This is easily generalized in more complicated applications, e.g., if the tasks are indexed in two directions.</p>
<p>However, we can improve on this a little by using <em>leapfrogging</em>. This is illustrated by </p>
<div class="fragment"><pre class="fragment">  vector&lt;unsigned long&gt; master_seed(Random::SeedVector());

  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; 10; ++i) { <span class="comment">// the main loop over tasks</span>

    Random r(master_seed);      <span class="comment">// use the same seed for each task</span>
    r.SetStride(10, i);         <span class="comment">// turn on leapfrogging with an offset i</span>
    ...
  }
</pre></div><p> where I have taken <em>k</em> = 10. In this example, each of the 10 tasks uses the <em>same</em> seed. However, the calls to SetStride cause task 0 to use the random numbers with indices 0, 10, 20, 31..., task 1 to use those with indices 1, 11, 21, 31, ..., and so on. This interval between random indices (10 in this example) is called the <em>stride</em>.</p>
<p>There is an overhead to this approach, since the numbers skipped over still have to be computed. However the cost of an unused number is only 1/3 of the cost of a number that is used. The relative cost might be even smaller if each tasks does an appreciably amount of additional computation for each random number it consumes. In the example described here, the overhead of when a stride is 4 is about 25%. This would be less in a more realistic example. The <em>advantage</em> of leapfrogging is that we retain the statistical benefits of using fewer longer sequences from the SFMT19937 generator.</p>
<p>We can combine the two approaches with </p>
<div class="fragment"><pre class="fragment">  <span class="comment">// Set master_seed to a &quot;unique&quot; vector</span>
  vector&lt;unsigned long&gt; master_seed(Random::SeedVector());
  master_seed.push_back(0);     <span class="comment">// Reserve an additional slot</span>
  <span class="keywordtype">int</span> l = 4;                    <span class="comment">// The leapfrogging stride</span>

  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; k; ++i) { <span class="comment">// the main loop over tasks</span>

    Random r;                   <span class="comment">// task specific Random</span>
    {
      vector&lt;unsigned long&gt; seed(master_seed); <span class="comment">// task specific seed</span>
      seed.back() = i / l;      <span class="comment">// include task id in seed</span>
      r.Reseed(seed);
      <span class="comment">// Turn on leapfrogging with an offset that depends on the task id</span>
      r.SetStride(l, i % l);
    }

    <span class="comment">// Do the work; last argument splits n exactly into k pieces</span>
    w[i] = <a class="code" href="RandomThread_8cpp.html#a024c7494a4662027dc2d4312577f2bce">dotrials</a>(r, d, (n * (i + 1))/k - (n * i)/k);
  }
</pre></div><p> With the numerical values given here, the 100 tasks use 25 sequences (each with a distinct seed), and 4000000 samples are taken from each sequence.</p>
<p>The final step is to cause the iterations of the main task loop to be carried out in parallel. With OpenMP, this is easily achieved by inserting the pragma </p>
<div class="fragment"><pre class="fragment"><span class="preprocessor">#pragma omp parallel for</span>
<span class="preprocessor"></span>  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; k; ++i) { <span class="comment">// the main loop over tasks</span>
    ...
  }
</pre></div><p> and compiling the code with -fopenmp, for g++, or turning on OpenMP support in Visual Studio (C/C++ -&gt; Language -&gt; OpenMP Support). OpenMP is easy to configure using cmake (see the file, examples/CMakeLists.txt)</p>
<p><a class="el" href="RandomThread_8cpp.html" title="Example of parallelization with RandomLib using threads.">RandomThread.cpp</a> is a complete program that carries out this computation. Running </p>
<div class="fragment"><pre class="fragment">
RandomThread -n 1e10 </pre></div><p> gives </p>
<div class="fragment"><pre class="fragment">
Estimate volume of a 4-dimensional sphere;
samples = -n 10000000000; tasks = -k 100; leapfrog stride = -l 4;
using RandomEngine&lt;SFMT19937&lt;Random_u32&gt;,MixerSFMT&gt;
with master seed = -s [64121,1307135579,11192,562213576,2011].
Estimated volume = 4.93475199 </pre></div><p> On an 8-core Intel Xeon, x86_64 2.66GHz machine with SSE2 instructions this takes about 70 sec. The <em>exact</em> result for the volume of a 4-dimensional sphere is pi<sup>2</sup>/2 = 4.9348022...</p>
<p>You can verify that goals 3&ndash;5 have been met by varying the number of threads allocated. This is accomplished by setting the environment variable <code>OMP_NUM_THREADS</code> at run time. In particular, setting this to 1 causes the code to be executed serially; thus </p>
<div class="fragment"><pre class="fragment">
env OMP_NUM_THREADS=1 RandomThread -n 1e10 -s 64121,1307135579,11192,562213576,2011
</pre></div><p> returns the <em>identical</em> result, 4.93475199 (but takes about 8 times longer).</p>
<center> Back to <a class="el" href="programming.html">Programming tips</a>. Forward to <a class="el" href="function.html">Function index</a>. Up to <a class="el" href="index.html#contents">Contents</a>. </center> </div></div>
<hr class="footer"/><address class="footer"><small>Generated on Sat Jan 21 2012 for RandomLib by&#160;
<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.7.4 </small></address>
</body>
</html>
